<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">

  <!-- SEO / Social -->
  <meta name="description" content="UDT is a novel unsupervised framework for discovering fine-grained, class-level transformation directions within diffusion models. By incorporating hierarchy information into contrastive learning, UDT structures the latent space to enable precise and semantically consistent edits, such as changing a dog's breed while preserving its pose.">
  <meta name="keywords" content="Diffusion Models, Unsupervised Learning, Latent Space Exploration, Fine-Grained Image Editing, Contrastive Learning, Image Transformation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="UDT: Unsupervised Discovery of Transformations between Fine-Grained Classes in Diffusion Models"/>
  <meta property="og:description" content="UDT is a novel unsupervised framework for discovering fine-grained, class-level transformation directions within diffusion models. By incorporating hierarchy information into contrastive learning, UDT structures the latent space to enable precise and semantically consistent edits, such as changing a dog's breed while preserving its pose."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <meta property="og:image" content="static/images/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="UDT: Unsupervised Discovery of Transformations between Fine-Grained Classes in Diffusion Models">
  <meta name="twitter:description" content="UDT is a novel unsupervised framework for discovering fine-grained, class-level transformation directions within diffusion models. By incorporating hierarchy information into contrastive learning, UDT structures the latent space to enable precise and semantically consistent edits, such as changing a dog's breed while preserving its pose.">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">

  <title>UDT: Unsupervised Discovery of Transformations</title>
  <link rel="icon" type="image/x-icon" href="static/images/ssu_icon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- CSS -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- JS (3rd party) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- MathJax config MUST come before the loader script -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true
      },
      options: {
        renderActions: {
          addMenu: [] // (선택) 우클릭 메뉴 비활성화 원하면 유지
        }
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              UDT: Unsupervised Discovery of Transformations between Fine-Grained Classes in Diffusion Models
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Youngjae Choi</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Hyunseo Koh</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/98hojae-jeong" target="_blank">Hojae Jeong</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Byungkwan Chae</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Sungyong Park</a>,
              </span>
              <span class="author-block">
                <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Heewon Kim</a><sup>†</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Soongsil University, Seoul, Republic of Korea <br>BMVC 2025
              </span>
              <span class="eql-cntrb">
                <small><br><sup>*</sup>Indicates Equal Contribution &nbsp; <sup>†</sup>Indicates Corresponding author</small>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!--
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
                -->

                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span> -->
              </div>
            </div>

          </div> <!-- column -->
        </div> <!-- columns -->
      </div> <!-- container -->
    </div> <!-- hero-body -->
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">TL;DR</h2>
          <div class="content has-text-justified">
            <p>
              UDT is an unsupervised framework that uses parent-class guided noise decomposition to achieve breed-to-breed translation across diverse domains like dogs, cats, flowers, and birds.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="title is-3 has-text-centered">Motivation</h2>
        <div class="item">
          <img src="static/images/figure1.jpg" alt="Motivation Figure" />
          <div class="content has-text-justified">
            <p>
              Existing unsupervised exploration methods, like NoiseCLR, struggle with fine-grained classes such as specific dog breeds. These approaches often remain at attribute-level edits, offering limited control over detailed visual attributes. For example, transformations using NoiseCLR frequently result in outcomes unrelated to the intended target or lead to only minor changes, such as a slight adjustment in fur color.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Diffusion models demonstrate excellent performance in image generation and synthesis.
              Effective and controllable editing with these models requires a deep understanding of their latent spaces, a primary focus of prior research.
              However, existing unsupervised exploration methods like NoiseCLR often remain at attribute-level edits, revealing limitations in complex fine-grained class transformations.
              To address this, we propose <code>UDT</code> (<b>U</b>nsupervised <b>D</b>iscovery of <b>T</b>ransformations), a novel framework that, while operating in a fully unsupervised setting, supports fine-grained class transformations by structuring the latent space in a hierarchy-aware manner.
              <code>UDT</code> leverages hierarchy-informed contrastive learning to disentangle class-defining traits using parent class guidance.
              This systematic approach structures the latent space to support diverse and meaningful transformations while ensuring semantic consistency and pose preservation.
              Experiments on dog, cat, bird, and flower datasets demonstrate that <code>UDT</code>'s performance over existing methods in generating coherent, diverse, and semantically accurate edits.
              These results suggest <code>UDT</code> is a scalable and effective approach for semantic latent space exploration in diffusion models.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Method</h2>

        <div class="item">
          <img src="static/images/figure2_v2.2.jpg" alt="method_figure"/>
          <div class="content has-text-justified">
            <p>
              The core of the framework is the decomposition of the predicted noise based on a parent class prompt $p$ (e.g. dog), a process that isolates class-specific signal $\Delta \mathcal{T}_k^n$ from the general parent-class attributes $\Delta \mathcal{P}_k^n$.
              The contrastive learning process then operates on these isolated $\Delta \mathcal{T}_k^n$ vectors.
              As illustrated in (a) and (b), the framework attracts positive pairs by pulling together $\Delta \mathcal{T}_k^n$ vectors that originate from different images but correspond to the same learnable direction (e.g., $c_1$ or $c_k$).
              Conversely, (c) shows the repulsion of negative pairs, where $\Delta \mathcal{T}_k^n$ vectors from the same source image but associated with different directions (e.g., $c_1$ or $c_k$) are pushed apart.
              This allows the framework to discover specific and consistent directions, such as $c_1$ for the "Bull Mastiff" and $c_k$ for "Golden Retriever".
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Quality Results of UDT</h2>
          <img src="static/images/figure3.jpg" alt="method_figure"/>
          <div class="content has-text-justified">
            <p>
              UDT discovers diverse and interpretable transformation directions within a single category and effectively generalizes this capability across various fine-grained domains such as dogs, cats, birds, and flowers. For instance, specific directions can transform a dog's breed into a Bulldog or a Golden Retriever with their distinct features, while others can accurately modify detailed attributes like a cat's fur color or a bird's plumage. However, a noticeable background shift is sometimes observed in the results, revealing a current limitation where the model does not perfectly disentangle the subject from the background.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Qualitative Comparison</h2>
          <img src="static/images/figure5_v2.jpg" alt="Qualitative comparison with other methods"/>
          <div class="content has-text-justified">
            <p>
              UDT demonstrates clear advantages in qualitative comparisons against recent methods. Unsupervised approaches like NoiseCLR and Concept Discovery often fail to find accurate transformation directions for specific dog breeds, a task where UDT consistently succeeds. Furthermore, UDT's performance is competitive with established editing methods. For instance, it renders the curly texture of a Toy Poodle more faithfully than LEDITS++ and excels at maintaining the original pose during edits, unlike Null-Text.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- TO DO : ADD VIDEO -->
  <!--
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  -->

  <!-- TO DO : ADD POSTER -->
  <!--
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>
        <iframe src="static/pdfs/sample.pdf" width="100%" height="550"></iframe>
      </div>
    </div>
  </section>
  -->

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{choi2025udt,
  title={UDT: Unsupervised Discovery of Transformations between Fine-Grained Classes in Diffusion Models},
  author={Choi, Youngjae and Koh, Hyunseo and Jeong, Hojae and Chae, Byungkwan and Park, Sungyong and Kim, Heewon},
  booktitle={British Machine Vision Conference (BMVC)},
  year={2025}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the
              <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>
              which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. <br>
              This website is licensed under a
              <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
                Creative Commons Attribution-ShareAlike 4.0 International License
              </a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
